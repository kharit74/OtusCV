{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad40e189",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "Использование Facial Landmarks в качестве Feature Estimator\n",
    "\n",
    "Цель:\n",
    "Создадить свой пайплайн Facial Recognition.\n",
    "\n",
    "Описание/Пошаговая инструкция выполнения домашнего задания:\n",
    "- Выберите Facial Detector по вкусу.\n",
    "- Выполните Face Alignment.\n",
    "- На это натравите Facial Landmarks Detector по выбору.\n",
    "- На этом обучите классификатор на предпочитаемом датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199fb208",
   "metadata": {},
   "source": [
    " # Пайплайн:\n",
    " ## __Facial Detector → Face Alignment → Facial Landmarks → Классификатор__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998ccb7",
   "metadata": {},
   "source": [
    "### 1. Выбор Facial Detector технологии\n",
    "MediaPipe Face Detection - актуальный, бесплатный, функциональный, не требовательный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f38dbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ce9b5",
   "metadata": {},
   "source": [
    "### 2. Выбор Face Alignment решения\n",
    "MediaPipe Face Mesh - 468 точек. Более чем достаточно для любых задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814b3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection = mediapipe.solutions.face_mesh # солюшн по лицу\n",
    "face_mesh = face_detection.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebd978",
   "metadata": {},
   "source": [
    "### 3. Наложение маски ~ извлечение маски\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ea23881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_face_landmarks(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if not results.multi_face_landmarks:\n",
    "        return None\n",
    "\n",
    "    landmarks = results.multi_face_landmarks[0]\n",
    "    points = np.array([[lm.x, lm.y, lm.z] for lm in landmarks.landmark])\n",
    "    return points.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1396833",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'Lesson 19/Homework/webcam_captures'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m label_to_name = {}\n\u001b[32m     11\u001b[39m dataset_path = \u001b[33m\"\u001b[39m\u001b[33mLesson 19/Homework/webcam_captures\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, person_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m     14\u001b[39m     label_to_name[idx] = person_name\n\u001b[32m     15\u001b[39m     person_dir = os.path.join(dataset_path, person_name)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] Системе не удается найти указанный путь: 'Lesson 19/Homework/webcam_captures'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "label_to_name = {}\n",
    "\n",
    "dataset_path = \"Lesson 19/Homework/webcam_captures\"\n",
    "\n",
    "for idx, person_name in enumerate(os.listdir(dataset_path)):\n",
    "    label_to_name[idx] = person_name\n",
    "    person_dir = os.path.join(dataset_path, person_name)\n",
    "    for img_file in os.listdir(person_dir):\n",
    "        img_path = os.path.join(person_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        landmarks = get_face_landmarks(img)\n",
    "        if landmarks is not None:\n",
    "            X.append(landmarks)\n",
    "            y.append(idx)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14570982",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Обучение классификатора\u001b[39;00m\n\u001b[32m      2\u001b[39m clf = SVC(kernel=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, probability=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m clf.fit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Сохранение модели\u001b[39;00m\n\u001b[32m      6\u001b[39m joblib.dump(clf, \u001b[33m'\u001b[39m\u001b[33mface_classifier.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Обучение классификатора\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Сохранение модели\n",
    "joblib.dump(clf, 'face_classifier.pkl')\n",
    "joblib.dump(label_to_name, 'label_to_name.pkl')\n",
    "\n",
    "# Оценка\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d5ae48",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'face_classifier.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Загрузка модели\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m clf = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mface_classifier.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m label_to_name = joblib.load(\u001b[33m'\u001b[39m\u001b[33mlabel_to_name.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m cap = cv2.VideoCapture(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KharitWinPC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode)\u001b[39m\n\u001b[32m    648\u001b[39m         obj = _unpickle(fobj)\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    651\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[32m    652\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    653\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    654\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    655\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'face_classifier.pkl'"
     ]
    }
   ],
   "source": [
    "# Загрузка модели\n",
    "clf = joblib.load('face_classifier.pkl')\n",
    "label_to_name = joblib.load('label_to_name.pkl')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    landmarks = get_face_landmarks(frame)\n",
    "    if landmarks is not None:\n",
    "        prediction = clf.predict([landmarks])\n",
    "        name = label_to_name[prediction[0]]\n",
    "        proba = clf.predict_proba([landmarks]).max()\n",
    "\n",
    "        # Отображение результата\n",
    "        cv2.putText(frame, f\"{name} ({proba*100:.1f}%)\", (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
